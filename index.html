<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <title>Simple cloudtrail searcher by rahulwa</title>
  </head>

  <body>
    <header>
      <div class="inner">
        <h1>Simple cloudtrail searcher</h1>
        <h2>Simplest AWS CloudTrail logs parser using Elasticsearch</h2>
        <a href="https://github.com/rahulwa/Simple-CloudTrail-Searcher" class="button"><small>View project on</small> GitHub</a>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h1>
<a id="cloudtrail-searcher-setup" class="anchor" href="#cloudtrail-searcher-setup" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>CloudTrail-Searcher-Setup</h1>

<p>Many administrators are facing an auditing problem because they can't search events older than 1 week in AWS CloudTrail console. Good new is that all logs are available in S3 bucket. But problem is <strong>How to search in it?</strong> I have an simple solution to this problem, <a href="https://www.elastic.co/products/elasticsearch">Elasticsearch</a> can be used here as search engine to the job.</p>

<h2>
<a id="why-elasticsearch" class="anchor" href="#why-elasticsearch" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Why Elasticsearch?</h2>

<ul>
<li>Elasticsearch consumes json document as an input and CloudTrail logs saved in S3 are in json format. So <strong>no conversions</strong>.</li>
<li>It provides a distributed, multitenant-capable full-text search engine with an HTTP web interface and schema-free JSON documents.</li>
</ul>

<h2>
<a id="setup-overview" class="anchor" href="#setup-overview" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Setup Overview</h2>

<ul>
<li>We are going to use Docker containers to setup and running Elasticsearch because of  universality. </li>
<li>Then we are going to download Cloudtrail logs from S3 to local machine.</li>
<li>Then will unzip and feed it to Elasticsearch.</li>
</ul>

<h2>
<a id="installing-prerequisite--docker-and-aws-cli" class="anchor" href="#installing-prerequisite--docker-and-aws-cli" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installing prerequisite : Docker and AWS cli</h2>

<ul>
<li>Install Docker on your OS using <a href="https://docs.docker.com/engine/installation/">Docker official guide</a>.</li>
<li>Install AWS cli following <a href="http://docs.aws.amazon.com/cli/latest/userguide/installing.html">AWS official guide</a>.</li>
<li>And start both programs.</li>
</ul>

<h2>
<a id="making-elasticsearch-container" class="anchor" href="#making-elasticsearch-container" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Making Elasticsearch container</h2>

<p>As we want to use <a href="https://github.com/mobz/elasticsearch-head">head plugin</a> (that will provides web gui), we have to include it in Elasticsearch docker image. Here we are making a <a href="https://docs.docker.com/engine/reference/builder/">Dockerfile</a> to build a custom image <a href="https://hub.docker.com/_/elasticsearch/">from official Elasticsearch docker image</a> and then installing head plugin in that image.</p>

<div class="highlight highlight-source-shell"><pre><span class="pl-c"># mkdir ~/es-head</span>
<span class="pl-c"># cd ~/es-head</span>
<span class="pl-c"># cat &gt; Dockerfile &lt;&lt;EOF</span>
<span class="pl-k">&gt;</span>FROM elasticsearch:2.3
<span class="pl-k">&gt;</span>
<span class="pl-k">&gt;</span>RUN /usr/share/elasticsearch/bin/plugin install mobz/elasticsearch-head
<span class="pl-k">&gt;</span>EOF
<span class="pl-c"># </span></pre></div>

<p>Now build a Docker image named “elasticsearch-head” from above Dockerfile(make sure that this directory should not contain anything other than Dockerfile).</p>

<div class="highlight highlight-source-shell"><pre><span class="pl-c"># ls </span>
Dockerfile
<span class="pl-c"># docker build -t elasticsearch-head:1 .</span></pre></div>

<p>Below command is use to create a <a href="https://docs.docker.com/engine/tutorials/dockervolumes/#/creating-and-mounting-a-data-volume-container">data only container</a> from above custom image that will print "DATA only ES" and then exits. We will use this container indirectly to store data of our actual service to /es_data/DATA on host.</p>

<div class="highlight highlight-source-shell"><pre><span class="pl-c"># mkdir -p /es_data/DATA</span>
<span class="pl-c"># docker run --name es-cloudtrail_DATA -v "/es_data/DATA":/usr/share/elasticsearch/data elasticsearch:2.3 echo "DATA only ES"</span>
DATA only ES
<span class="pl-c">#</span></pre></div>

<p>From <a href="https://docs.docker.com/v1.8/reference/commandline/run/">Docker run</a>, discription of above command.</p>

<pre><code>Usage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...]

Run a command in a new container
--name=""                     Assign a name to the container
-v, --volume=[]               Bind mount a volume
</code></pre>

<p>Finally we are actually launching Elasticsearch container that will be used for searching CloudTrail logs.</p>

<div class="highlight highlight-source-shell"><pre><span class="pl-c"># docker run -d --volumes-from es-cloudtrail_DATA -p 9200:9200 -p 9300:9300 --name es-cloudtrail  elasticsearch-head:1 -Des.node.name="es-cloudtrail"</span></pre></div>

<pre><code>Usage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...]

Run a command in a new container
-d, --detach=false            Run container in background and print container ID
--name=""                     Assign a name to the container
--volumes-from=[]             Mount volumes from the specified container(s)
-p, --publish=[]              Publish a container's port(s) to the host
</code></pre>

<h2>
<a id="downloading-cloudtrail-logs-from-s3" class="anchor" href="#downloading-cloudtrail-logs-from-s3" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Downloading CloudTrail logs from S3</h2>

<ul>
<li>Create an IAM user with read only access to s3.</li>
<li>Configure AWS cli using <a href="http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html">document</a> for above created IAM user.</li>
</ul>

<div class="highlight highlight-source-shell"><pre><span class="pl-c"># aws configure --profile cloudtrail</span>
AWS Access Key ID [None]: AKIAIOSFODNN7EXAMPLE
AWS Secret Access Key [None]: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
Default region name [None]: us-east-1
Default output format [None]: ENTER</pre></div>

<ul>
<li>Now we are downloading all CloudTail logs from S3 using below command, make sure that enough space is available.</li>
</ul>

<div class="highlight highlight-source-shell"><pre><span class="pl-c"># mkdir /es_data/traillogs</span>
<span class="pl-c"># aws s3 --profile cloudtrail cp s3://s3-traillogs-bucket-name/AWSLogs /es_data/traillogs/ --recursive</span></pre></div>

<blockquote>
<p>Inplace of "s3-traillogs-bucket-name", use your actual s3 bucket where traillogs are saved.</p>
</blockquote>

<h2>
<a id="sending-logs-to-elasticsearch" class="anchor" href="#sending-logs-to-elasticsearch" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Sending logs to Elasticsearch</h2>

<ul>
<li>Unzip all downloaded cloudtrail logs.</li>
</ul>

<div class="highlight highlight-source-shell"><pre><span class="pl-c"># gunzip -rv /es_data/traillogs</span></pre></div>

<p>We can use many things to send logs to Elasticsearch but simplest solution is to use <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/index-doc.html">HTTP PUT/POST</a> request as we have documents already in json format.</p>

<p>So now we are going to make a simple script that will do this jobs.</p>

<ul>
<li>First we will make a list of all traillogs file names with their full path. This is as simle is</li>
</ul>

<div class="highlight highlight-source-shell"><pre><span class="pl-c"># find /es_data/traillogs -name '*.json' -type f &gt; /es_data/logs.list</span></pre></div>

<ul>
<li>Now we will prefix a HTTP POST request for elasticsearch to  each line of above created logs.list file. This will make a POST request for each traillogs to elasticsearch.</li>
</ul>

<div class="highlight highlight-source-shell"><pre><span class="pl-c"># sed 's/^/curl -XPOST http://localhost:9200/AWS-account-name/old -d @/' /es_data/logs.list &gt; /es_data/logs.sh</span></pre></div>

<blockquote>
<p>here we are making a HTTP POST request to Elasticsearch on port 9200 with <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/index-doc.html#_autogenerating_ids">Index and type</a> as "AWS-account-name"(your AWS account name to identify easily) and "old"(useful in future).</p>
</blockquote>

<ul>
<li>Now make it executable and run.</li>
</ul>

<div class="highlight highlight-source-shell"><pre><span class="pl-c"># chmod u+x /es_data/logs.sh</span>
<span class="pl-c"># nohup bash /es_data/logs.sh &amp;</span></pre></div>

<ul>
<li>For space management, gzip again all downloaded traillogs.</li>
</ul>

<div class="highlight highlight-source-shell"><pre><span class="pl-c"># gzip -rv /es_data/traillogs</span></pre></div>

<p><strong>Now setup is complete and we are ready to search.</strong></p>

<h2>
<a id="searching" class="anchor" href="#searching" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Searching</h2>

<p>Now elasticsearch can be accessed by <a href="http://localhost:9200/_plugin/head">below URL</a>.</p>

<pre><code>http://localhost:9200/_plugin/head
</code></pre>

<p>Follow <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/search-in-depth.html">Elasticsearch documentation</a> and <a href="https://mobz.github.io/elasticsearch-head/">head plugin</a> for more on searching.</p>

<h2>
<a id="future" class="anchor" href="#future" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Future</h2>
        </section>

        <aside id="sidebar">
          <a href="https://github.com/rahulwa/Simple-CloudTrail-Searcher/zipball/master" class="button">
            <small>Download</small>
            .zip file
          </a>
          <a href="https://github.com/rahulwa/Simple-CloudTrail-Searcher/tarball/master" class="button">
            <small>Download</small>
            .tar.gz file
          </a>

          <p class="repo-owner"><a href="https://github.com/rahulwa/Simple-CloudTrail-Searcher"></a> is maintained by <a href="https://github.com/rahulwa">rahulwa</a>.</p>

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the Architect theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.</p>
        </aside>
      </div>
    </div>

  
  </body>
</html>
